---
title: "Forest Fire Area Prediction"
output: html_document
---

## Using a few ML algorithms, predict the area of a forest fire based on meteorological conditions, per the data set (<https://archive.ics.uci.edu/ml/datasets/forest+fires>) and approach outlined in [Cortez and Morais, 2007] P. Cortez and A. Morais. A Data Mining Approach to Predict Forest Fires using Meteorological Data.

### Compare the efficiency, error, and accuracy of each algorithm employed

### set working directory and load needed packages

```{r, setup}
knitr::opts_knit$set(root.dir = 'C:/Users/tscott/')
```

```{r}
# load packages
library(tidyverse) #for ggplot and dplyr
library(corrplot) #for correlation plots

```

### Get the data

Pre-downloaded from <https://archive.ics.uci.edu/ml/datasets/forest+fires>

```{r}
forestRaw <- read.csv("./OneDrive - Eastside Preparatory School/Courses/DataScience_2/data/forestfires.csv")
```

### From the documentation for the data set

Attribute information:

For more information, read [Cortez and Morais, 2007].

1.  X - x-axis spatial coordinate within the Montesinho park map: 1 to 9
2.  Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9
3.  month - month of the year: "jan" to "dec"
4.  day - day of the week: "mon" to "sun"
5.  FFMC - FFMC index from the FWI system: 18.7 to 96.20
6.  DMC - DMC index from the FWI system: 1.1 to 291.3
7.  DC - DC index from the FWI system: 7.9 to 860.6
8.  ISI - ISI index from the FWI system: 0.0 to 56.10
9.  temp - temperature in Celsius degrees: 2.2 to 33.30
10. RH - relative humidity in %: 15.0 to 100
11. wind - wind speed in km/h: 0.40 to 9.40
12. rain - outside rain in mm/m2 : 0.0 to 6.4
13. area - the burned area of the forest (in ha): 0.00 to 1090.84 (this output variable is very skewed towards 0.0, thus it may make sense to model with the logarithm transform).

Need to watch out for correlations, e.g., the Initial Spread Index (ISI) is a numeric rating of the expected rate of fire spread. It is based on wind speed and FFMC.

More deets: <https://wikifire.wsl.ch/tiki-indexbdbc.html?page=Canadian+forest+fire+weather+index+system>

### Inspect it and check for correlations

```{r}
summary(forestRaw)

# might want to set the month and day to factors
# but for correlation we can only use numeric values

forestNum <- forestRaw %>% select(-month, -day)
corrs <- cor(forestNum)
corrplot(corrs, order = 'hclust', addrect = 2)
```

### Quite a bit of correlation, especially between temp and the FWI values. Note that there are NO strong correlations with our goal, area

### Having variables that correlate strongly can both make your model worse and make it prone to overfitting - training well on the train data and poor performance on anything else

### When you read the paper by the authors [Cortez and Morais, 2007], you'll notice they took

$ln(area + 1)$

### (area + 1 to avoid log of zero) so the range wasn't so high. Let's do that. But we have to remember to do

$e^x-1$ afterward to get back to actual area

```{r}
forestNum <- forestNum %>% mutate(logArea = log(area+1))
summary(forestNum)
```

## multi-linear regression

### We'll naively try with all the numeric values. We're doing no normalization and not removing any that correlate with others, so we don't expect a great result.

```{r}
# We're going to use 80% of the rows to train the model
# then test it out on the remaining 20% of the data

# Create Training and Test data -
set.seed(732)  # setting seed to reproduce results of random sampling

# create row indices for training data
# sample will choose random row numbers (80% of the total number of rows)
trainingRowIndex <- sample(1:nrow(forestNum), 0.8*nrow(forestNum)) 

# use those row numbers to split up the data into rows for training 
# and rows for testing

# model training data are the rows that sample identified above
trainingData <- forestNum[trainingRowIndex, ]  

# model test data are the remaining rows
# the minus sign says  to take "all rows but those in trainingRowIndex"
testData  <- forestNum[-trainingRowIndex, ]

# make the model
# remember to use the logArea outcome rather than area
mlrModel <- lm(data=forestNum, logArea ~ .-area)
summary(mlrModel)
```

### Wow, only wind among the variables is significant, with high p-values for most 0.05 and an overall p-value of 0.218 with a terrible R-squared as well

### The median residual value is -0.585, and remember that is in log units so not very close to zero. We should look at a Q-Q plot and histogram of the residuals but it is safe to say they won't be good

```{r}
# Q-Q plot is a test for normally distributed residuals (2nd plot in the sequence)
# should be on a 45 deg line with little deviation
plot(mlrModel)

# histogram shows us something similar
ggplot(data=mlrModel, aes(x=mlrModel$residuals)) + geom_histogram()
```

## Finally, let's look at our main measure of goodness we'll be using, the RMSE (root mean squared error)

$RMSE = \sqrt{\frac{\sum(\hat{y}_i - y_i)^2}{n}}$

```{r}
# get values the model predicts for the test set
predictedArea <- predict(mlrModel, newdata=testData)

# calculation root mean squared error
(rmse_mlr <- sqrt(mean((predictedArea - testData$area) ^ 2, na.rm = TRUE)))

```

### We'll need that many times, so let's make an RMSE function to use

```{r}
myRMSE <- function(pred, obs) {
  return(sqrt(mean((pred - obs) ^ 2, na.rm = TRUE)))
}


# make sure it works
myRMSE(predictedArea,testData$area )
```

### Note that this is the error for the natural logged data and it still really sucks - we're way off of a decent model (which we might have predicted from the high median residuals and terrible stats)

## Do we give up? Heck no! There are other algorithms!
