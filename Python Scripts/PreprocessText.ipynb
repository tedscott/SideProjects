{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Learning of Key Phrases and Topics in Document Collections\n",
    "\n",
    "## Part 1: Text Preprocessing\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook is Part 1 in a series of 4, providing a step-by-step description of how to process and analyze the contents of a large collection of text documents in an unsupervised manner. Using Python packages and custom code examples, we have implemented the basic framework that combines key phrase learning and latent topic modeling as described in the paper entitled [\"Modeling Multiword Phrases with Constrained Phrases Tree for Improved Topic Modeling of Conversational Speech\"](http://people.csail.mit.edu/hazen/publications/Hazen-SLT-2012.pdf) which was originally presented in the 2012 IEEE Workshop on Spoken Language Technology.\n",
    "\n",
    "This notebook demonstrates how to preprocess the raw text from a collection of documents as precursor to applying the natural language processing techniques of unsupervised phrase learning and latent topic modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing NLTK Model for Sentence Tokenization\n",
    "\n",
    "\n",
    "NLTK is a collection of Python modules, prebuilt models and corpora that provides tools for complex natural language processing tasks. Because the toolkit is large, the base installation of NLTK only installs the core skeleton of the toolkit. Installation of specific modules, corpora and pre-built models can be invoked from within Python using a download functionality provided by NLTK that can be invoked from Python. \n",
    "\n",
    "In this notebook, we make use of the NLTK sentence tokenization capability which takes a long string of text and splits it into sentence units. The tokenizer requires the installation of the 'punkt'  tokenizer models. After importing nltk, the nltk.download() function can be used to download specific packages such as 'punkt'.\n",
    "\n",
    "For more information on NLTK see http://www.nltk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/tutorialuser/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# The first time you run NLTK you will need to download the 'punkt' models \n",
    "# for breaking text strings into individual sentences\n",
    "#nltk.download('punkt')\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Other Required Packages\n",
    "The 'pandas' package is used for handling and manipulating data frames. The 're' package is used for applying reguar expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas \n",
    "import re\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load full TSV file including a column of text\n",
    "frame = pandas.read_csv('../Data/CongressionalDocsData.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in corpus: 189088\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>Provides for a joint session of the Congress o...</td>\n",
       "      <td>1987-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>Salvadoran Foreign Assistance Reform Resolutio...</td>\n",
       "      <td>1989-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>Supports the President's actions to defend Sau...</td>\n",
       "      <td>1991-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>Declares that it is the sense of the Congress ...</td>\n",
       "      <td>1993-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hconres1-104</td>\n",
       "      <td>Recognizes the sacrifice of Army Chief Warrant...</td>\n",
       "      <td>1995-01-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               Text        Date\n",
       "0  hconres1-100  Provides for a joint session of the Congress o...  1987-01-06\n",
       "1  hconres1-101  Salvadoran Foreign Assistance Reform Resolutio...  1989-01-03\n",
       "2  hconres1-102  Supports the President's actions to defend Sau...  1991-01-03\n",
       "3  hconres1-103  Declares that it is the sense of the Congress ...  1993-01-05\n",
       "4  hconres1-104  Recognizes the sacrifice of Army Chief Warrant...  1995-01-04"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Total documents in corpus: %d\\n\" % len(frame))\n",
    "\n",
    "# Show the first five rows of the data in the frame\n",
    "frame[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provides for a joint session of the Congress on January 27, 1987, for a message from the President on the State of the Union.\n",
      "---\n",
      "Salvadoran Foreign Assistance Reform Resolution - Expresses the sense of the Congress that: (1) the U.S. foreign assistance program for El Salvador should be revised to promote a negotiated settlement and a reduction of human suffering; (2) the ratio of assistance should be reversed in FY 1990 so that the amount spent on the war effort is only one-third of the amount spent for reform and development activities; (3) such assistance should not be distributed in a manner which would promote the interests of any particular political party; (4) such assistance should be distributed through church-related and other nongovernmental organizations and international organizations selected by the Agency for International Development; and (5) the President should report quarterly to the Congress on the restructuring of such assistance, the economic results of such restructuring, and any reports of corruption in its distribution.\n",
      "---\n",
      "Supports the President's actions to defend Saudi Arabia and his diplomatic and economic initiatives to resolve the Persian Gulf crisis. Demands that Iraq immediately withdraw from Kuwait. Finds that the Constitution vests all power to declare war in the Congress. Declares that any offensive action against Iraq must be explicitly approved in advance by the Congress.\n"
     ]
    }
   ],
   "source": [
    "# Print the full text of the first three documents\n",
    "print(frame['Text'][0])\n",
    "print('---')\n",
    "print(frame['Text'][1])\n",
    "print('---')\n",
    "print(frame['Text'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text Data\n",
    "\n",
    "The CleanAndSplitText function below takes as input a list where each row element is a single cohesive long string of text, i.e. a \"document\". The function first splits each string by various forms of punctuation into chunks of text that are likely sentences, phrases or sub-phrases. The splitting is designed to prohibit the phrase learning process from using cross-sentence or cross-phrase word strings when learning phrases.\n",
    "\n",
    "The function creates a table where each row represents a chunk of text from the original documents. The DocIndex coulmn indicates the original row index from associated document in the input from which the chunk of text originated. The TextLine column contains the original text excluding the punctuation marks and HTML markup that have been during the cleaning process.The TextLineLower column contains a fully lower-cased verion of the text in the TextLIne column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CleanAndSplitText(textDataFrame):\n",
    "\n",
    "    textDataOut = [] \n",
    "   \n",
    "    # This regular expression is for section headers in the bill summaries that we wish to ignore\n",
    "    reHeaders = re.compile(r\" *TABLE OF CONTENTS:? *\"\n",
    "                           \"| *Title [IVXLC]+:? *\"\n",
    "                           \"| *Subtitle [A-Z]+:? *\"\n",
    "                           \"| *\\(Sec\\. \\d+\\) *\")\n",
    "\n",
    "    # This regular expression is for punctuation that we wish to clean out\n",
    "    # We also will split sentences into smaller phrase like units using this expression\n",
    "    rePhraseBreaks = re.compile(\"[\\\"\\!\\?\\)\\]\\}\\,\\:\\;\\*\\-]*\\s+\\([0-9]+\\)\\s+[\\(\\[\\{\\\"\\*\\-]*\"                             \n",
    "                                \"|[\\\"\\!\\?\\)\\]\\}\\,\\:\\;\\*\\-]+\\s+[\\(\\[\\{\\\"\\*\\-]*\"\n",
    "                                \"|\\.\\.+\"\n",
    "                                \"|\\s*\\-\\-+\\s*\"\n",
    "                                \"|\\s+\\-\\s+\"\n",
    "                                \"|\\:\\:+\"\n",
    "                                \"|\\s+[\\/\\(\\[\\{\\\"\\-\\*]+\\s*\"\n",
    "                                \"|[\\,!\\?\\\"\\)\\(\\]\\[\\}\\{\\:\\;\\*](?=[a-zA-Z])\"\n",
    "                                \"|[\\\"\\!\\?\\)\\]\\}\\,\\:\\;]+[\\.]*$\"\n",
    "                             )\n",
    "    \n",
    "    # Regex for underbars\n",
    "    regexUnderbar = re.compile('_')\n",
    "    \n",
    "    # Regex for space\n",
    "    regexSpace = re.compile(' +')\n",
    " \n",
    "    # Regex for sentence final period\n",
    "    regexPeriod = re.compile(\"\\.$\")\n",
    "\n",
    "    # Iterate through each document and do:\n",
    "    #    (1) Split documents into sections based on section headers and remove section headers\n",
    "    #    (2) Split the sections into sentences using NLTK sentence tokenizer\n",
    "    #    (3) Further split sentences into phrasal units based on punctuation and remove punctuation\n",
    "    #    (4) Remove sentence final periods when not part of a abbreviation \n",
    "\n",
    "    for i in range(0,len(frame)):\n",
    "        \n",
    "        # Extract one document from frame\n",
    "        docID = frame['ID'][i]\n",
    "        docText = frame['Text'][i] \n",
    "\n",
    "        # Set counter for output line count for this document\n",
    "        lineIndex=0;\n",
    "\n",
    "        # Split document into sections by finding sections headers and splitting on them \n",
    "        sections = reHeaders.split(docText)\n",
    "        \n",
    "        for section in sections:\n",
    "            # Split section into sentence using NLTK tokenizer \n",
    "            sentences = tokenize.sent_tokenize(section)\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                       \n",
    "                # Split each sentence into phrase level chunks based on punctuation\n",
    "                textSegs = rePhraseBreaks.split(sentence)\n",
    "                numSegs = len(textSegs)\n",
    "                \n",
    "                for j in range(0,numSegs):\n",
    "                    if len(textSegs[j])>0:\n",
    "                        # Convert underbars to spaces \n",
    "                        # Underbars are reserved for building the compound word phrases                   \n",
    "                        textSegs[j] = regexUnderbar.sub(\" \",textSegs[j])\n",
    "                    \n",
    "                        # Split out the words so we can specially handle the last word\n",
    "                        words = regexSpace.split(textSegs[j])\n",
    "                        phraseOut = \"\"\n",
    "                        last = len(words) -1\n",
    "                        for i in range(0, last):\n",
    "                            phraseOut += words[i] + \" \"\n",
    "                        # If the last word ends in a period then remove the period\n",
    "                        lastWord = regexPeriod.sub(\"\", words[last])\n",
    "                        # If the last word is an abbreviation like \"U.S.\"\n",
    "                        # then add the word final perios back on\n",
    "                        if \"\\.\" in lastWord:\n",
    "                            lastWord += \".\"\n",
    "                        phraseOut += lastWord    \n",
    "\n",
    "                        textDataOut.append([docID,lineIndex,phraseOut])\n",
    "                        lineIndex += 1\n",
    "                        \n",
    "    # Convert to pandas frame \n",
    "    frameOut = pandas.DataFrame(textDataOut, columns=['DocID','DocLine','CleanedText'])                      \n",
    "    \n",
    "    return frameOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    cleanedDataFrame = CleanAndSplitText(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing and reading text data to and from a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Writing the text data to file and reading it back in\n",
    "\n",
    "if False:\n",
    "    # Write frame with preprocessed text out to TSV file \n",
    "    cleanedDataFrame.to_csv('../Data/CongressionalDocsCleaned.tsv', sep='\\t',index=False)\n",
    "\n",
    "else:\n",
    "    # Read a cleaned data frame in from a TSV file\n",
    "    cleanedDataFrame = pandas.read_csv('../Data/CongressionalDocsCleaned.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the processed text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>DocLine</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>0</td>\n",
       "      <td>Provides for a joint session of the Congress o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>2</td>\n",
       "      <td>for a message from the President on the State ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>0</td>\n",
       "      <td>Salvadoran Foreign Assistance Reform Resolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>1</td>\n",
       "      <td>Expresses the sense of the Congress that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>2</td>\n",
       "      <td>the U.S. foreign assistance program for El Sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>3</td>\n",
       "      <td>the ratio of assistance should be reversed in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>4</td>\n",
       "      <td>such assistance should not be distributed in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>5</td>\n",
       "      <td>such assistance should be distributed through ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>6</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>7</td>\n",
       "      <td>the President should report quarterly to the C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>8</td>\n",
       "      <td>the economic results of such restructuring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>9</td>\n",
       "      <td>and any reports of corruption in its distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>0</td>\n",
       "      <td>Supports the President's actions to defend Sau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>1</td>\n",
       "      <td>Demands that Iraq immediately withdraw from Ku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>2</td>\n",
       "      <td>Finds that the Constitution vests all power to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>3</td>\n",
       "      <td>Declares that any offensive action against Ira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>0</td>\n",
       "      <td>Declares that it is the sense of the Congress ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>1</td>\n",
       "      <td>identify those individuals under the civil ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>3</td>\n",
       "      <td>advise them of the various vocational rehabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>4</td>\n",
       "      <td>including those administered by the U.S. Emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hconres1-104</td>\n",
       "      <td>0</td>\n",
       "      <td>Recognizes the sacrifice of Army Chief Warrant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hconres1-104</td>\n",
       "      <td>1</td>\n",
       "      <td>Recognizes the service of Army Chief Warrant O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hconres1-105</td>\n",
       "      <td>0</td>\n",
       "      <td>Expresses the sense of the Congress that retir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DocID  DocLine                                        CleanedText\n",
       "0   hconres1-100        0  Provides for a joint session of the Congress o...\n",
       "1   hconres1-100        1                                               1987\n",
       "2   hconres1-100        2  for a message from the President on the State ...\n",
       "3   hconres1-101        0    Salvadoran Foreign Assistance Reform Resolution\n",
       "4   hconres1-101        1           Expresses the sense of the Congress that\n",
       "5   hconres1-101        2  the U.S. foreign assistance program for El Sal...\n",
       "6   hconres1-101        3  the ratio of assistance should be reversed in ...\n",
       "7   hconres1-101        4  such assistance should not be distributed in a...\n",
       "8   hconres1-101        5  such assistance should be distributed through ...\n",
       "9   hconres1-101        6                                                and\n",
       "10  hconres1-101        7  the President should report quarterly to the C...\n",
       "11  hconres1-101        8         the economic results of such restructuring\n",
       "12  hconres1-101        9  and any reports of corruption in its distribution\n",
       "13  hconres1-102        0  Supports the President's actions to defend Sau...\n",
       "14  hconres1-102        1  Demands that Iraq immediately withdraw from Ku...\n",
       "15  hconres1-102        2  Finds that the Constitution vests all power to...\n",
       "16  hconres1-102        3  Declares that any offensive action against Ira...\n",
       "17  hconres1-103        0  Declares that it is the sense of the Congress ...\n",
       "18  hconres1-103        1  identify those individuals under the civil ser...\n",
       "19  hconres1-103        2                                                and\n",
       "20  hconres1-103        3  advise them of the various vocational rehabili...\n",
       "21  hconres1-103        4  including those administered by the U.S. Emplo...\n",
       "22  hconres1-104        0  Recognizes the sacrifice of Army Chief Warrant...\n",
       "23  hconres1-104        1  Recognizes the service of Army Chief Warrant O...\n",
       "24  hconres1-105        0  Expresses the sense of the Congress that retir..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedDataFrame[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provides for a joint session of the Congress on January 27\n",
      "1987\n",
      "for a message from the President on the State of the Union\n"
     ]
    }
   ],
   "source": [
    "print(cleanedDataFrame['CleanedText'][0])\n",
    "print(cleanedDataFrame['CleanedText'][1])\n",
    "print(cleanedDataFrame['CleanedText'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
