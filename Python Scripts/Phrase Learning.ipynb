{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Learning of Key Phrases and Topics in Document Collections\n",
    "\n",
    "## Part 2: Phrase Learning\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook is Part 2 of 4, in a series providing a step-by-step description of how to process and analyze the contents of a large collection of text documents in an unsupervised manner. Using Python packages and custom code examples, we have implemented the basic framework that combines key phrase learning and latent topic modeling as described in the paper entitled [\"Modeling Multiword Phrases with Constrained Phrases Tree for Improved Topic Modeling of Conversational Speech\"](http://people.csail.mit.edu/hazen/publications/Hazen-SLT-2012.pdf) which was originally presented in the 2012 IEEE Workshop on Spoken Language Technology.\n",
    "\n",
    "Although the paper examines the use of the technology for analyzing human-to-human conversations, the techniques are quite general and can be applied to a wide range of natural language data including news stories, legal documents, research publications, social media forum discussions, customer feedback forms, product reviews, and many more.\n",
    "\n",
    "Part 2 of the series shows how to learn the most salient phrases present in a large collection of documents. These phrases can be treated as single compound word units in down-stream processes such as topic modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas \n",
    "import re\n",
    "import math\n",
    "from operator import itemgetter\n",
    "from collections import namedtuple\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textFrame = pandas.read_csv('../Data/CongressionalDocsCleaned.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in cleaned text: 4050598\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>DocLine</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>0</td>\n",
       "      <td>Provides for a joint session of the Congress o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>2</td>\n",
       "      <td>for a message from the President on the State ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>0</td>\n",
       "      <td>Salvadoran Foreign Assistance Reform Resolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>1</td>\n",
       "      <td>Expresses the sense of the Congress that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>2</td>\n",
       "      <td>the U.S. foreign assistance program for El Sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>3</td>\n",
       "      <td>the ratio of assistance should be reversed in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>4</td>\n",
       "      <td>such assistance should not be distributed in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>5</td>\n",
       "      <td>such assistance should be distributed through ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>6</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>7</td>\n",
       "      <td>the President should report quarterly to the C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>8</td>\n",
       "      <td>the economic results of such restructuring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>9</td>\n",
       "      <td>and any reports of corruption in its distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>0</td>\n",
       "      <td>Supports the President's actions to defend Sau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>1</td>\n",
       "      <td>Demands that Iraq immediately withdraw from Ku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>2</td>\n",
       "      <td>Finds that the Constitution vests all power to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>3</td>\n",
       "      <td>Declares that any offensive action against Ira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>0</td>\n",
       "      <td>Declares that it is the sense of the Congress ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>1</td>\n",
       "      <td>identify those individuals under the civil ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>3</td>\n",
       "      <td>advise them of the various vocational rehabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>4</td>\n",
       "      <td>including those administered by the U.S. Emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hconres1-104</td>\n",
       "      <td>0</td>\n",
       "      <td>Recognizes the sacrifice of Army Chief Warrant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hconres1-104</td>\n",
       "      <td>1</td>\n",
       "      <td>Recognizes the service of Army Chief Warrant O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hconres1-105</td>\n",
       "      <td>0</td>\n",
       "      <td>Expresses the sense of the Congress that retir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DocID  DocLine                                        CleanedText\n",
       "0   hconres1-100        0  Provides for a joint session of the Congress o...\n",
       "1   hconres1-100        1                                               1987\n",
       "2   hconres1-100        2  for a message from the President on the State ...\n",
       "3   hconres1-101        0    Salvadoran Foreign Assistance Reform Resolution\n",
       "4   hconres1-101        1           Expresses the sense of the Congress that\n",
       "5   hconres1-101        2  the U.S. foreign assistance program for El Sal...\n",
       "6   hconres1-101        3  the ratio of assistance should be reversed in ...\n",
       "7   hconres1-101        4  such assistance should not be distributed in a...\n",
       "8   hconres1-101        5  such assistance should be distributed through ...\n",
       "9   hconres1-101        6                                                and\n",
       "10  hconres1-101        7  the President should report quarterly to the C...\n",
       "11  hconres1-101        8         the economic results of such restructuring\n",
       "12  hconres1-101        9  and any reports of corruption in its distribution\n",
       "13  hconres1-102        0  Supports the President's actions to defend Sau...\n",
       "14  hconres1-102        1  Demands that Iraq immediately withdraw from Ku...\n",
       "15  hconres1-102        2  Finds that the Constitution vests all power to...\n",
       "16  hconres1-102        3  Declares that any offensive action against Ira...\n",
       "17  hconres1-103        0  Declares that it is the sense of the Congress ...\n",
       "18  hconres1-103        1  identify those individuals under the civil ser...\n",
       "19  hconres1-103        2                                                and\n",
       "20  hconres1-103        3  advise them of the various vocational rehabili...\n",
       "21  hconres1-103        4  including those administered by the U.S. Emplo...\n",
       "22  hconres1-104        0  Recognizes the sacrifice of Army Chief Warrant...\n",
       "23  hconres1-104        1  Recognizes the service of Army Chief Warrant O...\n",
       "24  hconres1-105        0  Expresses the sense of the Congress that retir..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Total lines in cleaned text: %d\\n\" % len(textFrame))\n",
    "\n",
    "# Show the first five rows of the data in the frame\n",
    "textFrame[0:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lowercase Version of the Text Data\n",
    "\n",
    "Before learning phrases we lowercase the entire text corpus to ensure all casing variants for each word are collapsed into a single uniform variant used during the learning process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>DocLine</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>LowercaseText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>0</td>\n",
       "      <td>Provides for a joint session of the Congress o...</td>\n",
       "      <td>provides for a joint session of the congress o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>2</td>\n",
       "      <td>for a message from the President on the State ...</td>\n",
       "      <td>for a message from the president on the state ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>0</td>\n",
       "      <td>Salvadoran Foreign Assistance Reform Resolution</td>\n",
       "      <td>salvadoran foreign assistance reform resolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>1</td>\n",
       "      <td>Expresses the sense of the Congress that</td>\n",
       "      <td>expresses the sense of the congress that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>2</td>\n",
       "      <td>the U.S. foreign assistance program for El Sal...</td>\n",
       "      <td>the u.s. foreign assistance program for el sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>3</td>\n",
       "      <td>the ratio of assistance should be reversed in ...</td>\n",
       "      <td>the ratio of assistance should be reversed in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>4</td>\n",
       "      <td>such assistance should not be distributed in a...</td>\n",
       "      <td>such assistance should not be distributed in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>5</td>\n",
       "      <td>such assistance should be distributed through ...</td>\n",
       "      <td>such assistance should be distributed through ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>6</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>7</td>\n",
       "      <td>the President should report quarterly to the C...</td>\n",
       "      <td>the president should report quarterly to the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>8</td>\n",
       "      <td>the economic results of such restructuring</td>\n",
       "      <td>the economic results of such restructuring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>9</td>\n",
       "      <td>and any reports of corruption in its distribution</td>\n",
       "      <td>and any reports of corruption in its distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>0</td>\n",
       "      <td>Supports the President's actions to defend Sau...</td>\n",
       "      <td>supports the president's actions to defend sau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>1</td>\n",
       "      <td>Demands that Iraq immediately withdraw from Ku...</td>\n",
       "      <td>demands that iraq immediately withdraw from ku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>2</td>\n",
       "      <td>Finds that the Constitution vests all power to...</td>\n",
       "      <td>finds that the constitution vests all power to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>3</td>\n",
       "      <td>Declares that any offensive action against Ira...</td>\n",
       "      <td>declares that any offensive action against ira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>0</td>\n",
       "      <td>Declares that it is the sense of the Congress ...</td>\n",
       "      <td>declares that it is the sense of the congress ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>1</td>\n",
       "      <td>identify those individuals under the civil ser...</td>\n",
       "      <td>identify those individuals under the civil ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>3</td>\n",
       "      <td>advise them of the various vocational rehabili...</td>\n",
       "      <td>advise them of the various vocational rehabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>4</td>\n",
       "      <td>including those administered by the U.S. Emplo...</td>\n",
       "      <td>including those administered by the u.s. emplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hconres1-104</td>\n",
       "      <td>0</td>\n",
       "      <td>Recognizes the sacrifice of Army Chief Warrant...</td>\n",
       "      <td>recognizes the sacrifice of army chief warrant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hconres1-104</td>\n",
       "      <td>1</td>\n",
       "      <td>Recognizes the service of Army Chief Warrant O...</td>\n",
       "      <td>recognizes the service of army chief warrant o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hconres1-105</td>\n",
       "      <td>0</td>\n",
       "      <td>Expresses the sense of the Congress that retir...</td>\n",
       "      <td>expresses the sense of the congress that retir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DocID  DocLine                                        CleanedText  \\\n",
       "0   hconres1-100        0  Provides for a joint session of the Congress o...   \n",
       "1   hconres1-100        1                                               1987   \n",
       "2   hconres1-100        2  for a message from the President on the State ...   \n",
       "3   hconres1-101        0    Salvadoran Foreign Assistance Reform Resolution   \n",
       "4   hconres1-101        1           Expresses the sense of the Congress that   \n",
       "5   hconres1-101        2  the U.S. foreign assistance program for El Sal...   \n",
       "6   hconres1-101        3  the ratio of assistance should be reversed in ...   \n",
       "7   hconres1-101        4  such assistance should not be distributed in a...   \n",
       "8   hconres1-101        5  such assistance should be distributed through ...   \n",
       "9   hconres1-101        6                                                and   \n",
       "10  hconres1-101        7  the President should report quarterly to the C...   \n",
       "11  hconres1-101        8         the economic results of such restructuring   \n",
       "12  hconres1-101        9  and any reports of corruption in its distribution   \n",
       "13  hconres1-102        0  Supports the President's actions to defend Sau...   \n",
       "14  hconres1-102        1  Demands that Iraq immediately withdraw from Ku...   \n",
       "15  hconres1-102        2  Finds that the Constitution vests all power to...   \n",
       "16  hconres1-102        3  Declares that any offensive action against Ira...   \n",
       "17  hconres1-103        0  Declares that it is the sense of the Congress ...   \n",
       "18  hconres1-103        1  identify those individuals under the civil ser...   \n",
       "19  hconres1-103        2                                                and   \n",
       "20  hconres1-103        3  advise them of the various vocational rehabili...   \n",
       "21  hconres1-103        4  including those administered by the U.S. Emplo...   \n",
       "22  hconres1-104        0  Recognizes the sacrifice of Army Chief Warrant...   \n",
       "23  hconres1-104        1  Recognizes the service of Army Chief Warrant O...   \n",
       "24  hconres1-105        0  Expresses the sense of the Congress that retir...   \n",
       "\n",
       "                                        LowercaseText  \n",
       "0   provides for a joint session of the congress o...  \n",
       "1                                                1987  \n",
       "2   for a message from the president on the state ...  \n",
       "3     salvadoran foreign assistance reform resolution  \n",
       "4            expresses the sense of the congress that  \n",
       "5   the u.s. foreign assistance program for el sal...  \n",
       "6   the ratio of assistance should be reversed in ...  \n",
       "7   such assistance should not be distributed in a...  \n",
       "8   such assistance should be distributed through ...  \n",
       "9                                                 and  \n",
       "10  the president should report quarterly to the c...  \n",
       "11         the economic results of such restructuring  \n",
       "12  and any reports of corruption in its distribution  \n",
       "13  supports the president's actions to defend sau...  \n",
       "14  demands that iraq immediately withdraw from ku...  \n",
       "15  finds that the constitution vests all power to...  \n",
       "16  declares that any offensive action against ira...  \n",
       "17  declares that it is the sense of the congress ...  \n",
       "18  identify those individuals under the civil ser...  \n",
       "19                                                and  \n",
       "20  advise them of the various vocational rehabili...  \n",
       "21  including those administered by the u.s. emplo...  \n",
       "22  recognizes the sacrifice of army chief warrant...  \n",
       "23  recognizes the service of army chief warrant o...  \n",
       "24  expresses the sense of the congress that retir...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a lowercased version of the data and add it into the data frame\n",
    "lowercaseText = []\n",
    "for textLine in textFrame['CleanedText']:\n",
    "    lowercaseText.append(str(textLine).lower())\n",
    "textFrame['LowercaseText'] = lowercaseText;           \n",
    "            \n",
    "textFrame[0:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Supplemental Word Lists\n",
    "\n",
    "Words in the black list are completely ignored by the process and cannot be used in the creation of phrases. Words in the function word list can only be used in between content words in the creation of phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function for loading lists into dictionary hash tables\n",
    "def LoadListAsHash(filename):\n",
    "    listHash = {}\n",
    "    fp = open(filename)\n",
    "\n",
    "    # Read in lines one by one stripping away extra spaces, \n",
    "    # leading spaces, and trailing spaces and inserting each\n",
    "    # cleaned up line into a hash table\n",
    "    re1 = re.compile(' +')\n",
    "    re2 = re.compile('^ +| +$')\n",
    "    for stringIn in fp.readlines():\n",
    "        term = re2.sub(\"\",re1.sub(\" \",stringIn.strip('\\n')))\n",
    "        if term != '':\n",
    "            listHash[term] = 1\n",
    "\n",
    "    fp.close()\n",
    "    return listHash "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the black list of words to ignore \n",
    "blacklistHash = LoadListAsHash('../Data/black_list.txt')\n",
    "\n",
    "# Load the list of non-content bearing function words\n",
    "functionwordHash = LoadListAsHash('../Data/function_words.txt')\n",
    "\n",
    "# Add more terms to the function word list\n",
    "functionwordHash[\"foo\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute N-gram Statistics for Phrase Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is Step 1 for each iteration of phrase learning\n",
    "# We count the number of occurances of all 2-gram, 3-ngram, and 4-gram\n",
    "# word sequences \n",
    "def ComputeNgramStats(textData,functionwordHash,blacklistHash):\n",
    "    \n",
    "    # Create an array to store the total count of all ngrams up to 4-grams\n",
    "    # Array element 0 is unused, element 1 is unigrams, element 2 is bigrams, etc.\n",
    "    ngramCounts = [0]*5;\n",
    "       \n",
    "    # Create a list of structures to tabulate ngram count statistics\n",
    "    # Array element 0 is the array of total ngram counts,\n",
    "    # Array element 1 is a hash table of individual unigram counts\n",
    "    # Array element 2 is a hash table of individual bigram counts\n",
    "    # Array element 3 is a hash table of individual trigram counts\n",
    "    # Array element 4 is a hash table of individual 4-gram counts\n",
    "    ngramStats = [ngramCounts, {}, {}, {}, {}]\n",
    "          \n",
    "    # Create a regular expression for assessing validity of words\n",
    "    # for phrase modeling. The expression says words in phrases\n",
    "    # must either:\n",
    "    # (1) contain an alphabetic character, or \n",
    "    # (2) be the single charcater '&', or\n",
    "    # (3) be a one or two digit number\n",
    "    reWordIsValid = re.compile('[A-Za-z]|^&$|^\\d\\d?$');\n",
    "    \n",
    "    # Go through the text data line by line collecting count statistics\n",
    "    # for all valid n-grams that could appear in a potential phrase\n",
    "    numLines = len(textData)\n",
    "    for i in range(0,numLines):\n",
    "\n",
    "        # Split the text line into an array of words\n",
    "        wordArray = textData[i].split()\n",
    "        numWords = len(wordArray)\n",
    "        \n",
    "        # Create an array marking each word as valid or invalid\n",
    "        validArray = [];\n",
    "        for word in wordArray:\n",
    "            validArray.append(reWordIsValid.match(word) != None)        \n",
    "            \n",
    "        # Tabulate total raw ngrams for this line into counts for each ngram bin\n",
    "        # The total ngrams counts include the counts of all ngrams including those\n",
    "        # that we won't consider as parts of phrases\n",
    "        for j in range(1,5):\n",
    "            if j<=numWords:\n",
    "                ngramCounts[j] += numWords - j + 1 \n",
    "        \n",
    "        # Collect counts for viable phrase ngrams and left context sub-phrases\n",
    "        for j in range(0,numWords):\n",
    "            word = wordArray[j]\n",
    "\n",
    "            # Only bother counting the ngrams that start with a valid content word\n",
    "            # i.e., valids words not in the function word list or the black list\n",
    "            if ( ( word not in functionwordHash ) and ( word not in blacklistHash ) and validArray[j] ):\n",
    "\n",
    "                # Initialize ngram string with first content word and add it to unigram counts\n",
    "                ngramSeq = word \n",
    "                if ngramSeq in ngramStats[1]:\n",
    "                    ngramStats[1][ngramSeq] += 1\n",
    "                else:\n",
    "                    ngramStats[1][ngramSeq] = 1\n",
    "\n",
    "                # Count valid ngrams from bigrams up to 4-grams\n",
    "                stop = 0\n",
    "                k = 1\n",
    "                while (k<4) and (j+k<numWords) and not stop:\n",
    "                    n = k + 1\n",
    "                    nextNgramWord = wordArray[j+k]\n",
    "                    # Only count ngrams with valid words not in the blacklist\n",
    "                    if ( validArray[j+k] and nextNgramWord not in blacklistHash ):\n",
    "                        ngramSeq += \" \" + nextNgramWord\n",
    "                        if ngramSeq in ngramStats[n]:\n",
    "                            ngramStats[n][ngramSeq] += 1\n",
    "                        else:\n",
    "                            ngramStats[n][ngramSeq] = 1 \n",
    "                        k += 1\n",
    "                        if nextNgramWord not in functionwordHash:\n",
    "                            # Stop counting new ngrams after second content word in \n",
    "                            # ngram is reached and ngram is a viable full phrase\n",
    "                            stop = 1\n",
    "                    else:\n",
    "                        stop = 1\n",
    "    return ngramStats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Potential Phrases by the Weighted Pointwise Mutual Information of their Constituent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RankNgrams(ngramStats,functionwordHash,minCount):\n",
    "    # Create a hash table to store weighted pointwise mutual \n",
    "    # information scores for each viable phrase\n",
    "    ngramWPMIHash = {}\n",
    "        \n",
    "    # Go through each of the ngram tables and compute the phrase scores\n",
    "    # for the viable phrases\n",
    "    for n in range(2,5):\n",
    "        i = n-1\n",
    "        for ngram in ngramStats[n].keys():\n",
    "            ngramCount = ngramStats[n][ngram]\n",
    "            if ngramCount >= minCount:\n",
    "                wordArray = ngram.split()\n",
    "                # If the final word in the ngram is not a function word then\n",
    "                # the ngram is a valid phrase candidate we want to score\n",
    "                if wordArray[i] not in functionwordHash: \n",
    "                    leftNgram = wordArray[0]\n",
    "                    for j in range(1,i):\n",
    "                        leftNgram += ' ' + wordArray[j]\n",
    "                    rightWord = wordArray[i]\n",
    "                    \n",
    "                    # Compute the weighted pointwise mutual information (WPMI) for the phrase\n",
    "                    probNgram = float(ngramStats[n][ngram])/float(ngramStats[0][n])\n",
    "                    probLeftNgram = float(ngramStats[n-1][leftNgram])/float(ngramStats[0][n-1])\n",
    "                    probRightWord = float(ngramStats[1][rightWord])/float(ngramStats[0][1])\n",
    "                    WPMI = probNgram * math.log(probNgram/(probLeftNgram*probRightWord));\n",
    "\n",
    "                    # Add the phrase into the list of scored phrases only if WMPI is positive\n",
    "                    if WPMI > 0:\n",
    "                        ngramWPMIHash[ngram] = WPMI  \n",
    "    \n",
    "    # Create a sorted list of the phrase candidates\n",
    "    rankedNgrams = sorted(ngramWPMIHash, key=ngramWPMIHash.__getitem__, reverse=True)\n",
    "\n",
    "    # Force a memory clean-up\n",
    "    ngramWPMIHash = None\n",
    "    gc.collect()\n",
    "\n",
    "    return rankedNgrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Phrase Rewrites to Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ApplyPhraseRewrites(rankedNgrams,textData,learnedPhrases,                 \n",
    "                        maxPhrasesToAdd,maxPhraseLength,verbose):\n",
    "\n",
    "    # This function will consider at most maxRewrite \n",
    "    # new phrases to be added into the learned phrase \n",
    "    # list as specified by the calling fuinction\n",
    "    maxRewrite=maxPhrasesToAdd\n",
    "\n",
    "    # If the remaining number of proposed ngram phrases is less \n",
    "    # than the max allowed, then reset maxRewrite to the size of \n",
    "    # the proposed ngram phrases list\n",
    "    numNgrams = len(rankedNgrams)\n",
    "    if numNgrams < maxRewrite:\n",
    "        maxRewrite = numNgrams\n",
    "    \n",
    "    # Create empty hash tables to keep track of phrase overlap conflicts\n",
    "    leftConflictHash = {}\n",
    "    rightConflictHash = {}\n",
    "    \n",
    "    # Create an empty hash table collecting the set of rewrite rules\n",
    "    # to be applied during this iteration of phrase learning\n",
    "    ngramRewriteHash = {}\n",
    "    \n",
    "    # Precompile the regex for finding spaces in ngram phrases\n",
    "    regexSpace = re.compile(' ')\n",
    "\n",
    "    # Initialize some bookkeeping variables\n",
    "    numLines = len(textData)\n",
    "    numPhrasesAdded = 0\n",
    "    numConsidered = 0\n",
    "    lastSkippedNgram = \"\"\n",
    "    lastAddedNgram = \"\"\n",
    "  \n",
    "    # Collect list up to maxRewrite ngram phrase rewrites\n",
    "    stop = False\n",
    "    index = 0\n",
    "    while not stop:\n",
    "\n",
    "        # Get the next phrase to consider adding to the phrase list\n",
    "        inputNgram = rankedNgrams[index]\n",
    "\n",
    "        # Create the output compound word version of the phrase\n",
    "        # The extra space is added to make the regex rewrite easier\n",
    "        outputNgram = \" \" + regexSpace.sub(\"_\",inputNgram)\n",
    "\n",
    "        # Count the total number of words in the proposed phrase\n",
    "        numWords = len(outputNgram.split(\"_\"))\n",
    "\n",
    "        # Only add phrases that don't exceed the max phrase length\n",
    "        if (numWords <= maxPhraseLength):\n",
    "    \n",
    "            # Keep count of phrases considered for inclusion during this iteration\n",
    "            numConsidered += 1\n",
    "\n",
    "            # Extract the left and right words in the phrase to use\n",
    "            # in checks for phrase overlap conflicts\n",
    "            ngramArray = inputNgram.split()\n",
    "            leftWord = ngramArray[0]\n",
    "            rightWord = ngramArray[len(ngramArray)-1]\n",
    "\n",
    "            # Skip any ngram phrases that conflict with earlier phrases added\n",
    "            # These ngram phrases will be reconsidered in the next iteration\n",
    "            if (leftWord in leftConflictHash) or (rightWord in rightConflictHash): \n",
    "                if verbose: \n",
    "                    print (\"(%d) Skipping (context conflict): %s\" % (numConsidered,inputNgram))\n",
    "                lastSkippedNgram = inputNgram\n",
    "                \n",
    "            # If no conflict exists then add this phrase into the list of phrase rewrites     \n",
    "            else: \n",
    "                if verbose:\n",
    "                    print (\"(%d) Adding: %s\" % (numConsidered,inputNgram))\n",
    "                ngramRewriteHash[\" \" + inputNgram] = outputNgram\n",
    "                learnedPhrases.append(inputNgram) \n",
    "                lastAddedNgram = inputNgram\n",
    "                numPhrasesAdded += 1\n",
    "            \n",
    "            # Keep track of all context words that might conflict with upcoming\n",
    "            # propose phrases (even when phrases are skipped instead of added)\n",
    "            leftConflictHash[rightWord] = 1\n",
    "            rightConflictHash[leftWord] = 1\n",
    "\n",
    "            # Stop when we've considered the maximum number of phrases per iteration\n",
    "            if ( numConsidered >= maxRewrite ):\n",
    "                stop = True\n",
    "            \n",
    "        # Increment to next phrase\n",
    "        index += 1\n",
    "    \n",
    "        # Stop if we've reached the end of the ranked ngram list\n",
    "        if index >= len(rankedNgrams):\n",
    "            stop = True\n",
    "\n",
    "    # Now do the phrase rewrites over the entire set of text data\n",
    "    if numPhrasesAdded == 1:\n",
    "        # If only one phrase to add use a single regex rule to do this phrase rewrite        \n",
    "        inputNgram = \" \" + lastAddedNgram\n",
    "        outputNgram = ngramRewriteHash[inputNgram]\n",
    "        regexNgram = re.compile (r'%s(?= )' % re.escape(inputNgram)) \n",
    "        # Apply the regex over the full data set\n",
    "        for j in range(0,numLines):\n",
    "            textData[j] = regexNgram.sub(outputNgram, textData[j])\n",
    "    elif numPhrasesAdded > 1:\n",
    "        # Compile a single regex rule from the collected set of phrase rewrites for this iteration\n",
    "        ngramRegex = re.compile(r'%s(?= )' % \"|\".join(map(re.escape, ngramRewriteHash.keys())))\n",
    "        # Apply the regex over the full data set\n",
    "        for i in range(0,len(textData)):\n",
    "            # The regex substituion looks up the output string rewrite  \n",
    "            # in the hash table for each matched input phrase regex\n",
    "            textData[i] = ngramRegex.sub(lambda mo: ngramRewriteHash[mo.string[mo.start():mo.end()]], textData[i]) \n",
    "      \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the full iterative phrase learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ApplyPhraseLearning(textData,learnedPhrases,learningSettings):\n",
    "    \n",
    "    stop = 0\n",
    "    iterNum = 0\n",
    "\n",
    "    # Get the learning parameters from the structue passed in by thee calling function\n",
    "    maxNumPhrases = learningSettings.maxNumPhrases\n",
    "    maxPhraseLength = learningSettings.maxPhraseLength\n",
    "    functionwordHash = learningSettings.functionwordHash\n",
    "    blacklistHash = learningSettings.blacklistHash\n",
    "    verbose = learningSettings.verbose\n",
    "    minCount = learningSettings.minInstanceCount\n",
    "    \n",
    "    # Start timing the process\n",
    "    functionStartTime = time.clock()\n",
    "    \n",
    "    numPhrasesLearned = len(learnedPhrases)\n",
    "    print (\"Start phrase learning with %d phrases of %d phrases learned\" % (numPhrasesLearned,maxNumPhrases))\n",
    "\n",
    "    while not stop:\n",
    "        iterNum += 1\n",
    "                \n",
    "        # Start timing this iteration\n",
    "        startTime = time.clock()\n",
    " \n",
    "        # Collect ngram stats\n",
    "        ngramStats = ComputeNgramStats(textData,functionwordHash,blacklistHash)\n",
    "\n",
    "        # Rank ngrams\n",
    "        rankedNgrams = RankNgrams(ngramStats,functionwordHash,minCount)\n",
    "        \n",
    "        # Incorporate top ranked phrases into phrase list\n",
    "        # and rewrite the text to use these phrases\n",
    "        maxPhrasesToAdd = maxNumPhrases - numPhrasesLearned\n",
    "        if maxPhrasesToAdd > learningSettings.maxPhrasesPerIter:\n",
    "            maxPhrasesToAdd = learningSettings.maxPhrasesPerIter\n",
    "        ApplyPhraseRewrites(rankedNgrams,textData,learnedPhrases,maxPhrasesToAdd,maxPhraseLength,verbose)\n",
    "        numPhrasesAdded = len(learnedPhrases) - numPhrasesLearned\n",
    "\n",
    "        # Garbage collect\n",
    "        ngramStats = None\n",
    "        rankedNgrams = None\n",
    "        gc.collect();\n",
    "               \n",
    "        elapsedTime = time.clock() - startTime\n",
    "\n",
    "        numPhrasesLearned = len(learnedPhrases)\n",
    "        print (\"Iteration %d: Added %d new phrases in %.2f seconds (Learned %d of max %d)\" % \n",
    "               (iterNum,numPhrasesAdded,elapsedTime,numPhrasesLearned,maxNumPhrases))\n",
    "        \n",
    "        if numPhrasesAdded >= maxPhrasesToAdd or numPhrasesAdded == 0:\n",
    "            stop = 1\n",
    "        \n",
    "    # Remove the space padding at the start and end of each line\n",
    "    regexSpacePadding = re.compile('^ +| +$')\n",
    "    for i in range(0,len(textData)):\n",
    "        textData[i] = regexSpacePadding.sub(\"\",textData[i])\n",
    "    \n",
    "    gc.collect()\n",
    " \n",
    "    elapsedTime = time.clock() - functionStartTime\n",
    "    elapsedTimeHours = elapsedTime/3600.0;\n",
    "    print (\"*** Phrase learning completed in %.2f hours ***\" % elapsedTimeHours) \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Main top level execution of phrase learning functionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a structure defining the settings and word lists used during the phrase learning\n",
    "learningSettings = namedtuple('learningSettings',['maxNumPhrases','maxPhrasesPerIter',\n",
    "                                                  'maxPhraseLength','minInstanceCount'\n",
    "                                                  'functionwordHash','blacklistHash','verbose'])\n",
    "\n",
    "# If true it prints out the learned phrases to stdout buffer\n",
    "# while its learning. This will generate a lot of text to stdout, \n",
    "# so best to turn this off except for testing and debugging\n",
    "learningSettings.verbose = False\n",
    "\n",
    "# Maximium number of phrases to learn\n",
    "# If you want to test the code out quickly then set this to a small\n",
    "# value (e.g. 100) and set verbose to true when running the quick test\n",
    "learningSettings.maxNumPhrases = 25000\n",
    "\n",
    "# Maximum number of phrases to learn per iteration \n",
    "# Increasing this number may speed up processing but will affect the ordering of the phrases \n",
    "# learned and good phrases could be by-passed if the maxNumPhrases is set to a small number\n",
    "learningSettings.maxPhrasesPerIter = 200\n",
    "\n",
    "# Maximum number of words allowed in the learned phrases \n",
    "learningSettings.maxPhraseLength = 7\n",
    "\n",
    "# Minimum number of times a phrase must occur in the data to \n",
    "# be considered during the phrase learning process\n",
    "learningSettings.minInstanceCount = 5\n",
    "\n",
    "# This is a precreated hash table containing the list \n",
    "# of function words used during phrase learning\n",
    "learningSettings.functionwordHash = functionwordHash\n",
    "\n",
    "# This is a precreated hash table containing the list \n",
    "# of black list words to be ignored during phrase learning\n",
    "learningSettings.blacklistHash = blacklistHash\n",
    "\n",
    "# Initialize an empty list of learned phrases\n",
    "# If you have completed a partial run of phrase learning\n",
    "# and want to add more phrases, you can use the pre-learned \n",
    "# phrases as a starting point instead and the new phrases\n",
    "# will be appended to the list\n",
    "learnedPhrases = []\n",
    "\n",
    "# Create a copy of the original text data that will be used during learning\n",
    "# The copy is needed because the algorithm does in-place replacement of learned\n",
    "# phrases directly on the text data structure it is provided\n",
    "phraseTextData = []\n",
    "for textLine in textFrame['LowercaseText']:\n",
    "    phraseTextData.append(' ' + textLine + ' ')\n",
    "\n",
    "# Run the phrase learning algorithm\n",
    "if False:\n",
    "    ApplyPhraseLearning(phraseTextData,learnedPhrases,learningSettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learnedPhrasesFile = \"../Data/CongressionalDocsLearnedPhrases.txt\"\n",
    "phraseTextDataFile = \"../Data/CongressionalDocsPhraseTextData.txt\"\n",
    "\n",
    "if False:\n",
    "    # Write out the learned phrases to a text file\n",
    "    fp = open(learnedPhrasesFile, 'w')\n",
    "    for phrase in learnedPhrases:\n",
    "        fp.write(\"%s\\n\" % phrase)\n",
    "    fp.close()\n",
    "\n",
    "    # Write out the text data containing the learned phrases to a text file\n",
    "    fp = open(phraseTextDataFile, 'w')\n",
    "    for line in phraseTextData:\n",
    "        fp.write(\"%s\\n\" % line)\n",
    "    fp.close()\n",
    "\n",
    "\n",
    "if True:\n",
    "    # Read in the learned phrases from a text file\n",
    "    learnedPhrases = []\n",
    "    fp = open(learnedPhrasesFile, 'r')\n",
    "    for line in fp:\n",
    "        learnedPhrases.append(line.strip())\n",
    "    fp.close()\n",
    "\n",
    "    # Read in the learned phrases from a text file\n",
    "    phraseTextData = []\n",
    "    fp = open(phraseTextDataFile, 'r')\n",
    "    for line in fp:\n",
    "        phraseTextData.append(line.strip())\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['united states',\n",
       " 'directs the secretary',\n",
       " 'sets forth',\n",
       " 'internal revenue',\n",
       " 'authorizes appropriations',\n",
       " 'authorizes the secretary',\n",
       " 'requires the secretary',\n",
       " 'social security',\n",
       " 'expresses the sense',\n",
       " 'fiscal year']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnedPhrases[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['strike and sell',\n",
       " 'generic drug',\n",
       " 'crime control_act',\n",
       " 'address the needs',\n",
       " 'homeland_security and governmental_affairs',\n",
       " 'committed by an adult',\n",
       " 'subgrants to leas',\n",
       " 'party in interest',\n",
       " 'general education',\n",
       " 'special nuclear_material']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnedPhrases[5000:5010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['provides_for_a_joint session_of_the_congress on january_27',\n",
       " '1987',\n",
       " 'for a message_from_the_president on the state_of_the_union',\n",
       " 'salvadoran foreign_assistance reform resolution',\n",
       " 'expresses_the_sense_of_the_congress that',\n",
       " 'the u.s._foreign_assistance_program for el_salvador should be revised to promote a negotiated_settlement and a reduction of human suffering',\n",
       " 'the ratio of assistance should be reversed in fy 1990 so that the amount spent on the war effort is only one-third of the amount spent for reform and development_activities',\n",
       " 'such assistance should not be distributed in a manner which would promote the interests of any particular political_party',\n",
       " 'such assistance should be distributed through church-related and other nongovernmental_organizations and international_organizations selected by the agency_for_international_development',\n",
       " 'and',\n",
       " 'the president should report_quarterly to the congress on the restructuring of such assistance',\n",
       " 'the economic results of such restructuring',\n",
       " 'and any reports of corruption in its distribution',\n",
       " \"supports the president's actions to defend saudi_arabia and his diplomatic and economic initiatives to resolve the persian_gulf crisis\",\n",
       " 'demands that iraq immediately withdraw from kuwait']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phraseTextData[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add text with learned phrases back into data frame\n",
    "textFrame['TextWithPhrases'] = phraseTextData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>DocLine</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>LowercaseText</th>\n",
       "      <th>TextWithPhrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>0</td>\n",
       "      <td>Provides for a joint session of the Congress o...</td>\n",
       "      <td>provides for a joint session of the congress o...</td>\n",
       "      <td>provides_for_a_joint session_of_the_congress o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>1987</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>2</td>\n",
       "      <td>for a message from the President on the State ...</td>\n",
       "      <td>for a message from the president on the state ...</td>\n",
       "      <td>for a message_from_the_president on the state_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>0</td>\n",
       "      <td>Salvadoran Foreign Assistance Reform Resolution</td>\n",
       "      <td>salvadoran foreign assistance reform resolution</td>\n",
       "      <td>salvadoran foreign_assistance reform resolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>1</td>\n",
       "      <td>Expresses the sense of the Congress that</td>\n",
       "      <td>expresses the sense of the congress that</td>\n",
       "      <td>expresses_the_sense_of_the_congress that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>2</td>\n",
       "      <td>the U.S. foreign assistance program for El Sal...</td>\n",
       "      <td>the u.s. foreign assistance program for el sal...</td>\n",
       "      <td>the u.s._foreign_assistance_program for el_sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>3</td>\n",
       "      <td>the ratio of assistance should be reversed in ...</td>\n",
       "      <td>the ratio of assistance should be reversed in ...</td>\n",
       "      <td>the ratio of assistance should be reversed in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>4</td>\n",
       "      <td>such assistance should not be distributed in a...</td>\n",
       "      <td>such assistance should not be distributed in a...</td>\n",
       "      <td>such assistance should not be distributed in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>5</td>\n",
       "      <td>such assistance should be distributed through ...</td>\n",
       "      <td>such assistance should be distributed through ...</td>\n",
       "      <td>such assistance should be distributed through ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>6</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DocID  DocLine                                        CleanedText  \\\n",
       "0  hconres1-100        0  Provides for a joint session of the Congress o...   \n",
       "1  hconres1-100        1                                               1987   \n",
       "2  hconres1-100        2  for a message from the President on the State ...   \n",
       "3  hconres1-101        0    Salvadoran Foreign Assistance Reform Resolution   \n",
       "4  hconres1-101        1           Expresses the sense of the Congress that   \n",
       "5  hconres1-101        2  the U.S. foreign assistance program for El Sal...   \n",
       "6  hconres1-101        3  the ratio of assistance should be reversed in ...   \n",
       "7  hconres1-101        4  such assistance should not be distributed in a...   \n",
       "8  hconres1-101        5  such assistance should be distributed through ...   \n",
       "9  hconres1-101        6                                                and   \n",
       "\n",
       "                                       LowercaseText  \\\n",
       "0  provides for a joint session of the congress o...   \n",
       "1                                               1987   \n",
       "2  for a message from the president on the state ...   \n",
       "3    salvadoran foreign assistance reform resolution   \n",
       "4           expresses the sense of the congress that   \n",
       "5  the u.s. foreign assistance program for el sal...   \n",
       "6  the ratio of assistance should be reversed in ...   \n",
       "7  such assistance should not be distributed in a...   \n",
       "8  such assistance should be distributed through ...   \n",
       "9                                                and   \n",
       "\n",
       "                                     TextWithPhrases  \n",
       "0  provides_for_a_joint session_of_the_congress o...  \n",
       "1                                               1987  \n",
       "2  for a message_from_the_president on the state_...  \n",
       "3    salvadoran foreign_assistance reform resolution  \n",
       "4           expresses_the_sense_of_the_congress that  \n",
       "5  the u.s._foreign_assistance_program for el_sal...  \n",
       "6  the ratio of assistance should be reversed in ...  \n",
       "7  such assistance should not be distributed in a...  \n",
       "8  such assistance should be distributed through ...  \n",
       "9                                                and  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFrame[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for a message_from_the_president on the state_of_the_union'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFrame['TextWithPhrases'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Most Common Surface Form of Each Lower-Cased Word and Phrase\n",
    "\n",
    "The text data is lower cased in order to merge differently cased versions of the same word prior to doing topic modeling. In order to generate summaries of topics that will be learned, we would like to present the most likely surface form of a word to the user. For example, if a proper noun is converted to all lowercase characters for latent topic modeling, we want the user to see this proper name with its proper capitalization within summaries. The MapVocabToSurfaceForms() function achieves this by mapping every lowercased word and phrase used during latent topic modeling to its most common surface form in the text collection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MapVocabToSurfaceForms(textData):\n",
    "    surfaceFormCountHash = {}\n",
    "    vocabToSurfaceFormHash = {}\n",
    "    regexUnderBar = re.compile('_')\n",
    "    regexSpace = re.compile(' +')\n",
    "    regexClean = re.compile('^ +| +$')\n",
    "    \n",
    "    # First go through every line of text, align each word/phrase with\n",
    "    # it's surface form and count the number of times each surface form occurs\n",
    "    for i in range(0,len(textData)):    \n",
    "        origWords = regexSpace.split(regexClean.sub(\"\",str(textData['CleanedText'][i])))\n",
    "        numOrigWords = len(origWords)\n",
    "        newWords = regexSpace.split(regexClean.sub(\"\",str(textData['TextWithPhrases'][i])))\n",
    "        numNewWords = len(newWords)\n",
    "        origIndex = 0\n",
    "        newIndex = 0\n",
    "        while newIndex < numNewWords:\n",
    "            # Get the next word or phrase in the lower-cased text with phrases and\n",
    "            # match it to the original form of the same n-gram in the original text\n",
    "            newWord = newWords[newIndex]\n",
    "            phraseWords = regexUnderBar.split(newWord)\n",
    "            numPhraseWords = len(phraseWords)\n",
    "            matchedWords = origWords[origIndex]\n",
    "            origIndex += 1\n",
    "            for j in range(1,numPhraseWords):\n",
    "                matchedWords += \" \" + origWords[origIndex]\n",
    "                origIndex += 1\n",
    "                \n",
    "            # Now do the bookkeeping for collecting  the different surface form \n",
    "            # variations present for each lowercased word or phrase\n",
    "            if newWord in vocabToSurfaceFormHash:\n",
    "                if matchedWords not in vocabToSurfaceFormHash[newWord]:\n",
    "                    vocabToSurfaceFormHash[newWord].add(matchedWords)\n",
    "            else:\n",
    "                vocabToSurfaceFormHash[newWord] = set([matchedWords])\n",
    "\n",
    "            # Increment the counter for this surface form\n",
    "            if matchedWords not in surfaceFormCountHash:\n",
    "                surfaceFormCountHash[matchedWords] = 1\n",
    "            else:\n",
    "                surfaceFormCountHash[matchedWords] += 1\n",
    "   \n",
    "            if ( len(newWord) != len(matchedWords)):\n",
    "                print (\"##### Error #####\")\n",
    "                print (\"Bad Match: %s ==> %s \" % (newWord,matchedWords))\n",
    "                print (\"From line: %s\" % textData['TextWithPhrases'][i])\n",
    "                print (\"Orig text: %s\" % textData['CleanedText'][i])\n",
    "                \n",
    "                return False\n",
    "\n",
    "            newIndex += 1\n",
    "    # After aligning and counting, select the most common surface form for each\n",
    "\n",
    "    # word/phrase to be the canonical example shown to the user for that word/phrase\n",
    "    for ngram in vocabToSurfaceFormHash.keys():\n",
    "        maxCount = 0\n",
    "        bestSurfaceForm = \"\"\n",
    "        for surfaceForm in vocabToSurfaceFormHash[ngram]:\n",
    "            if surfaceFormCountHash[surfaceForm] > maxCount:\n",
    "                maxCount = surfaceFormCountHash[surfaceForm]\n",
    "                bestSurfaceForm = surfaceForm\n",
    "        if ngram != \"\":\n",
    "            if bestSurfaceForm == \"\":\n",
    "                print (\"Warning: NULL surface form for ngram '%s'\" % ngram)\n",
    "            else:\n",
    "                vocabToSurfaceFormHash[ngram] = bestSurfaceForm\n",
    "    \n",
    "    return vocabToSurfaceFormHash\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    vocabToSurfaceFormHash = MapVocabToSurfaceForms(textFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the mapping between model vocabulary and surface form mapping\n",
    "tsvFile = \"../Data/Vocab2SurfaceFormMapping.tsv\"\n",
    "\n",
    "if False:\n",
    "    fp = open(tsvFile, 'w')\n",
    "    for vocabItem in vocabToSurfaceFormHash:\n",
    "        if vocabItem != \"\":\n",
    "            strOut = \"%s\\t%s\\n\" % (vocabItem, vocabToSurfaceFormHash[vocabItem])\n",
    "            fp.write(strOut)\n",
    "    fp.close()\n",
    "    \n",
    "if True:\n",
    "    # Load surface form mappings here\n",
    "    vocabToSurfaceFormHash = {}\n",
    "    fp = open(tsvFile)\n",
    "\n",
    "    # Each line in the file has two tab separated fields;\n",
    "    # the first is the vocabulary item used during modeling\n",
    "    # and the second is its most common surface form in the \n",
    "    # original data\n",
    "    for stringIn in fp.readlines():\n",
    "        fields = stringIn.strip().split(\"\\t\")\n",
    "        if len(fields) != 2:\n",
    "            print (\"Warning: Bad line in surface form mapping file: %s\" % stringIn)\n",
    "        elif fields[0] == \"\" or fields[1] == \"\":\n",
    "            print (\"Warning: Bad line in surface form mapping file: %s\" % stringIn)\n",
    "        else:\n",
    "            vocabToSurfaceFormHash[fields[0]] = fields[1]\n",
    "    fp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "security\n",
      "Declares\n",
      "mental health\n",
      "El Salvador\n",
      "Department of the Interior\n"
     ]
    }
   ],
   "source": [
    "print (vocabToSurfaceFormHash['security'])\n",
    "print (vocabToSurfaceFormHash['declares'])\n",
    "print (vocabToSurfaceFormHash['mental_health'])\n",
    "print (vocabToSurfaceFormHash['el_salvador'])\n",
    "print (vocabToSurfaceFormHash['department_of_the_interior'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct the Full Processed Text of Each Document and Put it into a New Frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ReconstituteDocsFromChunks(textData, idColumnName, textColumnName):\n",
    "    dataOut = []\n",
    "    \n",
    "    currentDoc = \"\";\n",
    "    currentDocID = \"\";\n",
    "    \n",
    "    for i in range(0,len(textData)):\n",
    "        textChunk = textData[textColumnName][i]\n",
    "        docID = textData[idColumnName][i]\n",
    "        if docID != currentDocID:\n",
    "            if currentDocID != \"\":\n",
    "                dataOut.append([currentDocID, currentDoc])\n",
    "            currentDoc = textChunk\n",
    "            currentDocID = docID\n",
    "        else:\n",
    "            currentDoc += \" \" + textChunk\n",
    "    dataOut.append([currentDocID,currentDoc])\n",
    "    \n",
    "    frameOut = pandas.DataFrame(dataOut, columns=['DocID','ProcessedText'])\n",
    "    \n",
    "    return frameOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    docsFrame = ReconstituteDocsFromChunks(textFrame, 'DocID', 'TextWithPhrases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save processed text for each document back out to a TSV file\n",
    "if False:\n",
    "    docsFrame.to_csv('../Data/CongressionalDocsProcessed.tsv', sep='\\t', index=False)\n",
    "    \n",
    "if True: \n",
    "    docsFrame = pandas.read_csv('../Data/CongressionalDocsProcessed.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>ProcessedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hconres1-100</td>\n",
       "      <td>provides_for_a_joint session_of_the_congress o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hconres1-101</td>\n",
       "      <td>salvadoran foreign_assistance reform resolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hconres1-102</td>\n",
       "      <td>supports the president's actions to defend sau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hconres1-103</td>\n",
       "      <td>declares that it is the sense_of_the_congress ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hconres1-104</td>\n",
       "      <td>recognizes the sacrifice of army chief warrant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DocID                                      ProcessedText\n",
       "0  hconres1-100  provides_for_a_joint session_of_the_congress o...\n",
       "1  hconres1-101  salvadoran foreign_assistance reform resolutio...\n",
       "2  hconres1-102  supports the president's actions to defend sau...\n",
       "3  hconres1-103  declares that it is the sense_of_the_congress ...\n",
       "4  hconres1-104  recognizes the sacrifice of army chief warrant..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsFrame[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'salvadoran foreign_assistance reform resolution expresses_the_sense_of_the_congress that the u.s._foreign_assistance_program for el_salvador should be revised to promote a negotiated_settlement and a reduction of human suffering the ratio of assistance should be reversed in fy 1990 so that the amount spent on the war effort is only one-third of the amount spent for reform and development_activities such assistance should not be distributed in a manner which would promote the interests of any particular political_party such assistance should be distributed through church-related and other nongovernmental_organizations and international_organizations selected by the agency_for_international_development and the president should report_quarterly to the congress on the restructuring of such assistance the economic results of such restructuring and any reports of corruption in its distribution'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsFrame['ProcessedText'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
